{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAxOLwdZGjXf"
      },
      "source": [
        "# Using an LLM as a PII Data Judge for Secure Logging\n",
        "\n",
        "This notebook demonstrates an advanced approach to PII (Personally Identifiable Information) detection in application logs. Instead of relying on rigid regular expressions (regex), we use a Large Language Model (LLM) as a sophisticated \"judge\" to analyze log messages for sensitive data.\n",
        "\n",
        "### Core Concepts:\n",
        "1.  **LLM as Judge**: We prompt the LLM with a specific set of instructions to classify a log message as either containing PII or not.\n",
        "2.  **Context-Awareness**: The LLM can understand context that regex cannot (e.g., distinguishing a name like \"John Smith\" from a product name).\n",
        "3.  **`logging.Filter` Integration**: We integrate this LLM judge into Python's standard `logging` module for a clean, practical implementation.\n",
        "\n",
        "### ⚠️ **Important Disclaimer: Production Readiness** ⚠️\n",
        "This is a proof-of-concept. Using an LLM for **synchronous, real-time log filtering** is generally not feasible due to:\n",
        "- **Latency**: API calls can take seconds, which would cripple application performance.\n",
        "- **Cost**: Each log line would become an API call, leading to high costs.\n",
        "- **Reliability**: Network or API failures would break your logging.\n",
        "\n",
        "**Realistic Use Cases**: This approach is better suited for **asynchronous log post-processing**, security auditing, or training a smaller, local model."
      ],
      "id": "SAxOLwdZGjXf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhNYVm6XGjXi"
      },
      "source": [
        "### Cell 1: Setup and API Key Configuration\n",
        "\n",
        "First, we install the necessary Google library and configure our API key.\n",
        "\n",
        "**Action Required**: You must add your Gemini API key to Colab's secrets manager with the name `GEMINI_API_KEY`."
      ],
      "id": "GhNYVm6XGjXi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ExCE3inGjXi",
        "outputId": "344aa2e8-c828-4091-8fe7-4672ef159c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gemini API configured successfully.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai\n",
        "\n",
        "import logging\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from enum import Enum, auto\n",
        "\n",
        "# --- Configure the Gemini API ---\n",
        "try:\n",
        "    # Use the userdata API to securely access the secret.\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    print(\"✅ Gemini API configured successfully.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"🛑 Error: Secret 'GEMINI_API_KEY' not found.\")\n",
        "    print(\"Please add your API key to the Colab Secrets manager (key icon on the left) with that name.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "id": "_ExCE3inGjXi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMaNNYJbGjXj"
      },
      "source": [
        "### Cell 2: The LLM PII \"Judge\" Logic\n",
        "\n",
        "Here we define the core function that communicates with the LLM. The prompt is carefully engineered to force a simple, machine-parsable response (`PII_DETECTED` or `NO_PII`).\n",
        "\n",
        "We also add a simple cache to avoid re-analyzing identical log messages, which saves time and money."
      ],
      "id": "oMaNNYJbGjXj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9okTHA1YGjXj",
        "outputId": "cc2c157b-cf90-4389-ec3d-7ac437bc4102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM PII judge function defined.\n"
          ]
        }
      ],
      "source": [
        "# A simple in-memory cache to avoid repeated API calls for the same message\n",
        "llm_pii_cache = {}\n",
        "\n",
        "def is_pii_detected_by_llm(log_message: str) -> bool:\n",
        "    \"\"\"Asks the LLM to judge if a log message contains PII.\"\"\"\n",
        "    if log_message in llm_pii_cache:\n",
        "        return llm_pii_cache[log_message]\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "    # The prompt is critical. It defines the role, task, and expected output format.\n",
        "    prompt = f\"\"\"\n",
        "    You are a highly-trained security and privacy analysis model. Your task is to determine if the following log message contains Personally Identifiable Information (PII).\n",
        "    PII includes, but is not limited to: full names, email addresses, phone numbers, Social Security Numbers (SSNs), credit card numbers, physical addresses, driver's license numbers, or specific medical information.\n",
        "\n",
        "    Analyze the following log message:\n",
        "    '{log_message}'\n",
        "\n",
        "    Respond with ONLY ONE of the following two words: PII_DETECTED or NO_PII.\n",
        "    Do not provide any explanation, punctuation, or other text.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        result_text = response.text.strip()\n",
        "\n",
        "        is_pii = (result_text == 'PII_DETECTED')\n",
        "        llm_pii_cache[log_message] = is_pii # Cache the result\n",
        "        return is_pii\n",
        "    except Exception as e:\n",
        "        # Fail-safe: If the API call fails, assume it might contain PII and log an error.\n",
        "        print(f\"LLM API call failed: {e}. Defaulting to PII detected.\")\n",
        "        llm_pii_cache[log_message] = True\n",
        "        return True\n",
        "\n",
        "print(\"LLM PII judge function defined.\")"
      ],
      "id": "9okTHA1YGjXj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QExB2GPcGjXj"
      },
      "source": [
        "### Cell 3: The Custom `logging.Filter`\n",
        "\n",
        "This class integrates our LLM judge into the logging pipeline. If the LLM detects PII, the filter modifies the log message to add a warning prefix or returns `False` to block it entirely, depending on the policy."
      ],
      "id": "QExB2GPcGjXj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kie5kmXUGjXj",
        "outputId": "857da927-6594-4df8-b385-739d3be3c6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PiiFilterLLM class defined.\n"
          ]
        }
      ],
      "source": [
        "class Policy(Enum):\n",
        "    \"\"\"Defines the action to take when PII is detected by the LLM.\"\"\"\n",
        "    WARN_AND_LOG = auto()\n",
        "    BLOCK = auto()\n",
        "\n",
        "class PiiFilterLLM(logging.Filter):\n",
        "    \"\"\"A logging filter that uses an LLM to detect PII.\"\"\"\n",
        "    def __init__(self, policy: Policy = Policy.BLOCK):\n",
        "        super().__init__()\n",
        "        self.policy = policy\n",
        "\n",
        "    def filter(self, record: logging.LogRecord) -> bool:\n",
        "        original_message = record.getMessage()\n",
        "\n",
        "        if is_pii_detected_by_llm(original_message):\n",
        "            if self.policy == Policy.BLOCK:\n",
        "                # By returning False, we stop the log from being processed further.\n",
        "                return False\n",
        "            elif self.policy == Policy.WARN_AND_LOG:\n",
        "                # Modify the message in-place to add a security warning.\n",
        "                record.msg = f\"[PII DETECTED BY LLM] {original_message}\"\n",
        "                record.args = []\n",
        "\n",
        "        # Return True to allow the (potentially modified) record to be logged.\n",
        "        return True\n",
        "\n",
        "print(\"PiiFilterLLM class defined.\")"
      ],
      "id": "Kie5kmXUGjXj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0s8dVn-GjXj"
      },
      "source": [
        "### Cell 4: Demonstration with 10 Test Cases\n",
        "\n",
        "Now we'll configure a logger with our `PiiFilterLLM` and test it against a variety of log messages. The first run might be slow as it needs to make API calls. Subsequent runs will be faster due to the cache.\n",
        "\n",
        "The policy is set to `BLOCK`, so any message the LLM identifies as containing PII will be completely suppressed."
      ],
      "id": "C0s8dVn-GjXj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "9i16RN-dGjXk",
        "outputId": "235b94ac-a65d-4d92-a979-79fefbcb6e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running logs through LLM Filter (Policy: BLOCK) ---\n",
            "NOTE: Any message judged as PII will be silently dropped.\n",
            "\n",
            "--- Test Case #1 ---\n",
            "--- Test Case #2 ---\n",
            "--- Test Case #3 ---\n",
            "--- Test Case #4 ---\n",
            "--- Test Case #5 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - Service health check passed with status 200 OK.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Test Case #6 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - Failed to retrieve record with correlation_id=f47ac10b-58cc-4372-a567-0e02b2c3d479.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Test Case #7 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - SQL error: new row for relation \"users\" violates check constraint \"users_email_check\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Test Case #8 ---\n",
            "--- Test Case #9 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - User mentioned they lived on a street named 'Elm' but did not give a full address.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Test Case #10 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - Transaction declined for Visa card ending in 4242.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Caching Demonstration ---\n",
            "Re-running a sensitive log. This should be much faster and still be blocked.\n",
            "\n",
            "--- Log Analysis Complete ---\n"
          ]
        }
      ],
      "source": [
        "# --- Logger Setup ---\n",
        "logger = logging.getLogger(\"LLM_PII_SecureApp\")\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.propagate = False # Crucial to prevent duplicate output in Colab\n",
        "\n",
        "# Clear any previous handlers to ensure a clean run\n",
        "if logger.hasHandlers():\n",
        "    logger.handlers.clear()\n",
        "\n",
        "handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "\n",
        "# --- Add the LLM Filter ---\n",
        "llm_filter = PiiFilterLLM(policy=Policy.BLOCK)\n",
        "handler.addFilter(llm_filter)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "# --- 10 Test Examples ---\n",
        "test_cases = [\n",
        "    # 1. Obvious PII (Regex would also catch)\n",
        "    \"User login failed for jane.doe@example.com.\",\n",
        "    # 2. Obvious PII (Regex would also catch)\n",
        "    \"Customer support called user at 555-867-5309.\",\n",
        "    # 3. Subtle PII (Harder for Regex)\n",
        "    \"Processing request for customer Johnathan Smith.\",\n",
        "    # 4. Subtle PII (Very hard for Regex)\n",
        "    \"Shipment #54321 failed for delivery to 123 Oak Avenue, Springfield, IL.\",\n",
        "    # 5. Benign - No PII\n",
        "    \"Service health check passed with status 200 OK.\",\n",
        "    # 6. Benign - Technical ID\n",
        "    \"Failed to retrieve record with correlation_id=f47ac10b-58cc-4372-a567-0e02b2c3d479.\",\n",
        "    # 7. Benign - Technical Error\n",
        "    \"SQL error: new row for relation \\\"users\\\" violates check constraint \\\"users_email_check\\\"\",\n",
        "    # 8. Tricky PII (Name in context)\n",
        "    \"Note from support ticket T5678: Spoke with Bob Johnson regarding the outage.\",\n",
        "    # 9. Tricky Negative (Looks like PII but lacks specifics)\n",
        "    \"User mentioned they lived on a street named 'Elm' but did not give a full address.\",\n",
        "    # 10. Financial PII\n",
        "    \"Transaction declined for Visa card ending in 4242.\"\n",
        "]\n",
        "\n",
        "print(\"--- Running logs through LLM Filter (Policy: BLOCK) ---\")\n",
        "print(\"NOTE: Any message judged as PII will be silently dropped.\\n\")\n",
        "\n",
        "for i, message in enumerate(test_cases):\n",
        "    print(f\"--- Test Case #{i+1} ---\")\n",
        "    logger.info(message)\n",
        "\n",
        "print(\"\\n--- Caching Demonstration ---\")\n",
        "print(\"Re-running a sensitive log. This should be much faster and still be blocked.\")\n",
        "logger.info(\"Processing request for customer Johnathan Smith.\")\n",
        "\n",
        "print(\"\\n--- Log Analysis Complete ---\")"
      ],
      "id": "9i16RN-dGjXk"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}